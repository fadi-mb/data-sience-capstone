{
 "cells": [
  {
   "source": [
    "# Segmenting and Clustering Neighborhoods in Toronto | Part-1  \n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start by creating a new Notebook for this assignment.\n",
    "\n",
    "2. Use the Notebook to build the code to scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M, in order to obtain the data that is in the table of postal codes and to transform the data into a pandas dataframe.\n",
    "For this assignment, you will be required to explore and cluster the neighborhoods in Toronto.\n",
    "\n",
    "3. To create the above dataframe:\n",
    "\n",
    ". \n",
    "- The dataframe will consist of three columns: PostalCode, Borough, and Neighborhood.\n",
    "- Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\n",
    "- More than one neighborhood can exist in one postal code area. For example, in the table on the Wikipedia page, you will notice that M5A is listed twice and has two neighborhoods: Harbourfront and Regent Park. These two rows will be combined into one row with the neighborhoods separated with a comma as shown in row 11 in the above table.\n",
    "- If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough. So for the 9th cell in the table on the Wikipedia page, the value of the Borough and the Neighborhood columns will be Queen's Park.\n",
    "- Clean your Notebook and add Markdown cells to explain your work and any assumptions you are making.\n",
    "- In the last cell of your notebook, use the .shape method to print the number of rows of your dataframe.\n",
    ".\n",
    "\n",
    "\n",
    "4. Submit a link to your Notebook on your Github repository. (10 marks)\n",
    "\n",
    "Note: There are different website scraping libraries and packages in Python. For scraping the above table, you can simply use pandas to read the table into a pandas dataframe.\n",
    "\n",
    "Another way, which would help to learn for more complicated cases of web scraping is using the BeautifulSoup package. Here is the package's main documentation page: http://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "\n",
    "The package is so popular that there is a plethora of tutorials and examples on how to use it. Here is a very good Youtube video on how to use the BeautifulSoup package: https://www.youtube.com/watch?v=ng2o98k983k\n",
    "\n",
    "Use pandas, or the BeautifulSoup package, or any other way you are comfortable with to transform the data in the table on the Wikipedia page into the above pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BeautifulSoup Scraping List of Postal Codes of Given Wikipedia Page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n",
    "extracting_data = requests.get(url).text.replace('\\n','')\n",
    "wiki_data = BeautifulSoup(extracting_data, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting content of PostalCode HTML table as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "toronto.shape =  (181, 3)\n"
     ]
    }
   ],
   "source": [
    "column_names = ['Postalcode','Borough','Neighborhood']\n",
    "toronto = pd.DataFrame(columns = column_names)\n",
    "\n",
    "content = wiki_data.find('div', class_='mw-parser-output')\n",
    "table = content.table.tbody\n",
    "postcode = 0\n",
    "borough = 0\n",
    "neighborhood = 0\n",
    "\n",
    "for tr in table.find_all('tr'):\n",
    "    i = 0\n",
    "    for td in tr.find_all('td'):\n",
    "        if i == 0:\n",
    "            postcode = td.text\n",
    "            i = i + 1\n",
    "        elif i == 1:\n",
    "            borough = td.text\n",
    "            i = i + 1\n",
    "        elif i == 2: \n",
    "            neighborhood = td.text.strip('\\n').replace(']','')\n",
    "    toronto = toronto.append({'Postalcode': postcode,'Borough': borough,'Neighborhood': neighborhood},ignore_index=True)\n",
    "print('toronto.shape = ' , toronto.shape)\n",
    "toronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore cells with a borough that is Not assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto = toronto[ (toronto.Borough!='Not assigned') & (toronto.Borough!= 0) ]\n",
    "toronto.reset_index(drop = True, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting neighborhood values to be the same as the borough for Not assigned neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toronto.loc[toronto.Neighborhood == 'Not assigned','Neighborhood'] = toronto.loc[toronto.Neighborhood == 'Not assigned','Borough']     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining neighborhoods for each postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = toronto.groupby(['Postalcode','Borough'])['Neighborhood'].apply(', '.join).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning | Drop None rows of df and row which contains 'Not assigned' value | All \"Not assigned\" will be replace to 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "empty = 'Not assigned'\n",
    "df = df[(df.Postalcode != empty ) & (df.Borough != empty) & (df.Neighborhood != empty)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(103, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Postalcode      Borough                            Neighborhood\n",
       "0        M1B  Scarborough                          Malvern, Rouge\n",
       "1        M1C  Scarborough  Rouge Hill, Port Union, Highland Creek\n",
       "2        M1E  Scarborough       Guildwood, Morningside, West Hill\n",
       "3        M1G  Scarborough                                  Woburn\n",
       "4        M1H  Scarborough                               Cedarbrae"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postalcode</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>Scarborough</td>\n      <td>Malvern, Rouge</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>Scarborough</td>\n      <td>Rouge Hill, Port Union, Highland Creek</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>Scarborough</td>\n      <td>Guildwood, Morningside, West Hill</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>Scarborough</td>\n      <td>Woburn</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>Scarborough</td>\n      <td>Cedarbrae</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('toronto.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrame contains 103 rows\n"
     ]
    }
   ],
   "source": [
    "print('DataFrame contains {} rows'.format(df.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}